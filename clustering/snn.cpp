// Class automatically generated by Dev-C++ New Class wizard

#include "snn.h" // class's header file

using std::string;

const int snn::NNDefault;
const float snn::strongDefault;        // # of weak links / total # of links
const float snn::topicDefault;  // # of topics     / total # of points
const float snn::noiseDefault;  // percentage of noise points
const float snn::mergeDefault;  // percentage of links to be used for merging
const float snn::labelDefault;  // label*merge threshold=label threshold ... no labeling by default

// class constructor
snn::snn(string datasetName, string fileResultName, t_similarities sim = euclidean,
           int auxNN = NNDefault, float auxstrong = strongDefault, float auxtopic = topicDefault, 
           float auxnoise = noiseDefault, float auxmerge = mergeDefault, float auxlabel = labelDefault)
{
	dataset = datasetName;
	fileResult = fileResultName;
    similarity = sim;
    NN = auxNN;
    strong = auxstrong;
    topic = auxtopic;
    noise = auxnoise;
    merge = auxmerge;
    label  = auxlabel;
}

snn::snn(string datasetName, string fileResultName, t_similarities sim = euclidean)
{
	dataset = datasetName;
	fileResult = fileResultName;
    similarity = sim;
    NN = NNDefault;
    strong = strongDefault;        // # of weak links / total # of links
    topic = topicDefault;  // # of topics     / total # of points
    noise = noiseDefault;  // percentage of noise points
    merge = mergeDefault;  // percentage of links to be used for merging
    label = labelDefault;  // label*merge threshold=label threshold ... no labeling by default
}


snn::snn()
{
	dataset = "";
	fileResult = "";
    similarity = euclidean;
    NN = NNDefault;
    strong = strongDefault;        // # of weak links / total # of links
    topic = topicDefault;  // # of topics     / total # of points
    noise = noiseDefault;  // percentage of noise points
    merge = mergeDefault;  // percentage of links to be used for merging
    label = labelDefault;  // label*merge threshold=label threshold ... no labeling by default
}

snn::snn(std::string datasetName, std::string fileResultName, t_similarities sim, std::string parameters)
{
    dataset = datasetName;
	fileResult = fileResultName;
    similarity = sim;
    NN = NNDefault;
    strong = strongDefault;        // # of weak links / total # of links
    topic = topicDefault;  // # of topics     / total # of points
    noise = noiseDefault;  // percentage of noise points
    merge = mergeDefault;  // percentage of links to be used for merging
    label = labelDefault;  // label*merge threshold=label threshold ... no labeling by default
    
    typedef boost::tokenizer<boost::char_separator<char> > tokenizer;
    boost::char_separator<char> sep("\t ");
    tokenizer tokens(parameters, sep);
    
    tokenizer::iterator ti = tokens.begin();
    while (ti != tokens.end())
    {
        if (*ti == "-NN")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            NN = boost::lexical_cast<int>(*ti);
            if ((NN == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "CN: " << CN << std::endl;
        }
        else if (*ti == "-sim")  
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            if (*ti == "euclidean")
            {
                similarity = euclidean;
            } 
            else if (*ti == "pearson")
            {
	      similarity = pearson;
            } 
            else
            {                
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "sim: " << similarity << std::endl;
        }
        else if (*ti == "-strong")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            strong = boost::lexical_cast<float>(*ti);
            if ((strong == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "vt: " << VT << std::endl;
        }
        else if (*ti == "-topic")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            topic = boost::lexical_cast<float>(*ti);
            if ((topic == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "rt: " << RT << std::endl;
        }
        else if (*ti == "-noise")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            noise = boost::lexical_cast<float>(*ti);;
            if ((noise == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "et: " << ET << std::endl;
        }
        else if (*ti == "-merge")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            merge = boost::lexical_cast<float>(*ti);
            if ((merge == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "a: " << A1 << " " << A2 << " " << A3 << std::endl;
        }
        else if (*ti == "-label")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            label = boost::lexical_cast<float>(*ti);
            if ((label == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "a: " << A1 << " " << A2 << " " << A3 << std::endl;
        }
        else std::cout << "Invalid parameter: " << *ti << std::endl;
        ti++;
    }  
}


snn::snn(std::string parameters)
{
    dataset = "";
	fileResult = "";
    similarity = euclidean;
    NN = NNDefault;
    strong = strongDefault;        // # of weak links / total # of links
    topic = topicDefault;  // # of topics     / total # of points
    noise = noiseDefault;  // percentage of noise points
    merge = mergeDefault;  // percentage of links to be used for merging
    label = labelDefault;  // label*merge threshold=label threshold ... no labeling by default
    
    typedef boost::tokenizer<boost::char_separator<char> > tokenizer;
    boost::char_separator<char> sep("\t ");
    tokenizer tokens(parameters, sep);
    
    tokenizer::iterator ti = tokens.begin();
    while (ti != tokens.end())
    {
        if (*ti == "-NN")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            NN = boost::lexical_cast<int>(*ti);
            if ((NN == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "CN: " << CN << std::endl;
        }
        else if (*ti == "-sim")  
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            if (*ti == "euclidean")
            {
                similarity = euclidean;
            } 
            else if (*ti == "pearson")
            {
                similarity = pearson;
            } 
            else
            {                
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "sim: " << similarity << std::endl;
        }
        else if (*ti == "-strong")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            strong = boost::lexical_cast<float>(*ti);
            if ((strong == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "vt: " << VT << std::endl;
        }
        else if (*ti == "-topic")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            topic = boost::lexical_cast<float>(*ti);
            if ((topic == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "rt: " << RT << std::endl;
        }
        else if (*ti == "-noise")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            noise = boost::lexical_cast<float>(*ti);;
            if ((noise == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "et: " << ET << std::endl;
        }
        else if (*ti == "-merge")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            merge = boost::lexical_cast<float>(*ti);
            if ((merge == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "a: " << A1 << " " << A2 << " " << A3 << std::endl;
        }
        else if (*ti == "-label")
        {
            ti++;
            if (ti == tokens.end()) {std::cout << "Error in the parameters." << std::endl; break;}
            label = boost::lexical_cast<float>(*ti);
            if ((label == 0) && (*ti != "0"))
            {
                std::cout << "Invalid parameter value: " << *ti << std::endl;
            }
            //std::cout << "a: " << A1 << " " << A2 << " " << A3 << std::endl;
        }
        else std::cout << "Invalid parameter: " << *ti << std::endl;
        ti++;
    }  
}


// class destructor
//snn::~snn()
//{
//	 insert your code here
//}

snn::snn(const snn &a)
{
    dataset = a.dataset;
    fileResult = a.fileResult;
    similarity = a.similarity;
    NN = a.NN;
    strong = a.strong;
    topic = a.topic;
    noise = a.noise;
    merge = a.merge;
    label  = a.label;
    p = a.p;
} 

snn & snn::operator = (const snn &a)
{
    dataset = a.dataset;
    fileResult = a.fileResult;
    similarity = a.similarity;
    NN = a.NN;
    strong = a.strong;
    topic = a.topic;
    noise = a.noise;
    merge = a.merge;
    label  = a.label;
    p = a.p;
} 


//partition snn::operator()()
cpartition snn::run()
{ 
    string command, sim;
//    string sim;
    //fs::path fileClu("", fs::native);

    //string buffer;
    //string buffer;
    
    // similarities available in tho software snn
    // 0 - dot product
    // 1 - cosine measure
    // 2 - jaccard coefficient (binary)
    // 3 - euclidean distance
    // 4 - correlation coefficient (dense format only)
    switch(similarity) 
    {
        case euclidean:   sim = "3"; break;
        case pearson:   sim = "4"; break;
//      default:   statement sequence; break;
    }
    
//    if (parameters == "")
//    {
//        command = "snn " + dataset + " " + fileResult + " " +  sim;
//    } 
//    else
//    {
//        command = "snn " + dataset + " " + fileResult + " " +  sim + " " + parameters;
//    }
    
    if (runningSystem == mywindows)
        command = "snn " + dataset + " 3 " + sim + " -out " + fileResult; // 3 is the dense format of the dataset
    else
        command = "snn " + dataset + " 3 " + sim + " -out " + fileResult; // 3 is the dense format of the dataset

    if (NN != NNDefault)    
    {
        command += " -NN ";
        command += boost::lexical_cast<string>(NN);
    }  
  
    if (strong != strongDefault)    
    {
        command += " -strong ";
        command += boost::lexical_cast<string>(strong);

    }

    if (topic != topicDefault)    
    {
        //std::cout << "ET:" << ET << std::endl;
        command += " -topic ";
        command += boost::lexical_cast<string>(topic);
    }

    if (noise != noiseDefault)    
    {
        command += " -noise ";
        command += boost::lexical_cast<string>(noise);
    }
    
    if (merge != mergeDefault)    
    {
        command += " -merge ";
        command += boost::lexical_cast<string>(merge);
    }

    if (label != labelDefault)    
    {
        command += " -label ";
        command += boost::lexical_cast<string>(label);
    }

    //std::cout << command << std::endl;

    // run the algorithm snn
    system(command.c_str());
   
    string fileClu = fileResult + ".clu";
    p.loadPartition(fileClu);
    p.printPartition(fileClu); // to make the labeling starts at 1

    return p;

}

void snn::changeDataset(std::string datasetName)
{
     dataset = datasetName;
}

void snn::changeResultFile(std::string fileResultName)
{
     fileResult = fileResultName;
}

void snn::changeSimilarity(t_similarities sim)
{
     similarity = sim;
}

void snn::changeNN(int value) 
{
     NN = value;
}

void snn::changeStrong(float value) 
{
     strong = value;
}

void snn::changeTopic(float value) 
{
     topic = value;
}
 
void snn::changeNoise(float value)
{
     noise = value;
}

void snn::changeMerge(float value)
{
     merge = value;
}

void snn::changeLabel(float value) 
{
     label = value;
}

cpartition snn::getPartition()
{
    return p;
}

//snn::t_cells snn::getCells()
//{    
//     
////    t_cells clusterCenters;
//
//    fs::ifstream file2,file3;
//    char line[maxFileLine];
//    string line2, identifier, s;
//
//    typedef boost::tokenizer<boost::char_separator<char> > tokenizer;
//    boost::char_separator<char> sep("\t ");
//    std::map<std::string, std::vector<double>, cmp> pat;
// 
//    // load the correspondence between nodes and clusters in snn results
//    std::map<int, int > clustersNodes;
//    int node, cluster;    
//    string fileCorrespondence = fileResult + ".clu.correspondence";
//    //string fileCorrespondence = fileAlgorithmPartition.string() + ".clu.correspondence";
//    //std::cout << fileCorrespondence << std::endl;
//    file2.open(fileCorrespondence);
//    if (!file2.good()) 
//    {
//        std::cout << "\nError in the file '" << fileCorrespondence << "'\n";
//        getchar();
//    }    
//    while (!file2.eof())
//    {
//        file2 >> cluster >> node;
//        //std::cout << cluster << std::endl;
//        //getchar();
//        clustersNodes[node] = cluster;
//    }
//    file2.close();
//    
//    //getchar();
//
//    std::map<int, std::vector<double> > clustersCenters;
//
//    // read the cells of the file .cod generated with snnrray 6.0
//    string filesnnCells = fileResult + ".cod";
//    //string filesnnCells = fileAlgorithmPartition.string() + ".cod";
//    //char nodeWord[10], sign[10];
//    file3.open(filesnnCells);
//    if (!file3.good()) 
//    {
//        std::cout << "\nError in the file '" << filesnnCells << "'\n";
//        getchar();
//    }
//    
//    file3.getline(line, maxFileLine);
//    file3.getline(line, maxFileLine);
//    
//    while (!file3.eof())
//    {
//        file3.getline(line, maxFileLine);
//        
//        sscanf(line, "%*s%d", &node);
////        strcmp(sign, "->")
//        if (strstr(line, "->"))
//        {
//            file3.ignore(maxFileLine, '\n');
//            //std::cout << "tem sign" << std::endl;
////            std::cout << nodeWord << std::endl;
//            //std::cout << node << std::endl;
//        }
//        else
//        {     
//            //std::cout << "entrou no else" << std::endl;     
//            //std::cout << node << std::endl;
//            file3.getline(line, maxFileLine);
//            line2 = line;
//            tokenizer tokens(line2, sep);
//            //tokens.assign(line2, sep);
//            for (tokenizer::iterator tok_iter = tokens.begin(); tok_iter != tokens.end(); ++tok_iter)
//            {
//                s = *tok_iter; 
//                //std::cout << s << std::endl;
//                clustersCenters[clustersNodes[node]].insert(clustersCenters[clustersNodes[node]].end(), atof(s.c_str()));
//                //pat[identifier].insert(pat[identifier].end(), atof(s.c_str())); 
//            //std::cout << s.c_str() << std::endl;
//            }
//        }
//   }
//    file3.close();
//
////        std::map<int, std::vector<double> >::iterator patIterator;        
////        for (patIterator = clustersCenters.begin(); 
////        patIterator != clustersCenters.end(); 
////        patIterator++)    
////        {
////            std::cout << "First " << (*patIterator).first << std::endl;
////            for (std::vector<double>::iterator v = (*patIterator).second.begin(); v != (*patIterator).second.end(); ++v)
////            { 
////                std::cout << "Second " << *v << std::endl; 
////            }
////        }
////getchar();
//
//    return clustersCenters;
//}

